# Andruil is Undermining American Security for Profit

## Who is Andruil? 

Andruil is a realtively new startup that is making waves in both the software and defense industries. run by the ex-Occulus founder Palmer Lucky, Andruil essentially embraces a complete about face on the use of AI in military applications that is taking place in the American defense industry right now. Whereas a few years ago, it was beyond taboo for silicon valley venuture-backed startups to openly partner with the DoD, today, Andruil is bucking this trend in trying to compete for top government contracts with the likes of Boeing, Lockheed Martin, and General Dynamics.

But Andruil isn't cut from the same cloth as those old-school defense contractors. Whereas Boeing and Lockheed's bread is buttered by contracts to build the next F-22 fighter jet or super heavy lift aircraft, Andruil is lazor focus on selling autonomous systems for military and security applications. Andruil's publically known products include an autonomous sentry tower now deployed along the American-Mexican border, autonomous submersibles, and more. Andruil critizes both its competition and American policy makers for being asleep at the wheel by not embracing more AI in military applications. They claim that not developing and deploying these technologies is seeding the technological upper hand in future conflicts to states like China and Russia, that might not have the same qualms about developing and using such technologies in their militaries. 

What are people's reservations about using more autonomous technologies in military applications? The reservations are many and different according to who you ask. According to Lucky, in an interview with Bloomberg, he claims that at least part of this reservation is based in employees of consumer technology companies not being told upfront that they would be working on military applications. Thus, the logic goes, that these employees would see the likes of their employeers such as the Google or Amazon's of the world, openly embracing these technologies as a "bait and switch" and a betrayal of the promise made to them, of what they would be working on when they were hired. Other objections stem from nebulous moral concerns about purity and not wanting to be associated with the military-industrial complex in anyway. 

Putting aside the merit of these reservations, one thing that ties them together is that they are typically based in some moral, ethical, or emotional appeal. Working on projects that kill people is evil, full stop. If this was the extent of objections to Andruil's crusade, than I would have to join in with Lucky in critizing these hypothetical objections for a certain naivety. All of us living in American society benefit and have our very livlihood constituted by acts of violence, no matter how abstracted away those acts remain. From teachers, to cops, to software engineers, to directors, if you go back far enough, violence played a pivotal role in creating space for a civil society that make all of our present-day lives possible. This truth, no matter how inconviennt it may be, gets in the way of any appeal to not "participating" in acts of violence, by not working directly on projects that enact those violent acts on people.

But what if there was a deeper, more grounded, much more practical reason that apply autonomous systems to military industries was a misguided venture? What if there were grounds to believe that Andruil's tactical approach, of applying AI to military projects, actually directly undermined and pushed us further away from their stated strategic aims of increased national security? Well that's exactly what is happening. The more automomous, disconnected, and inhuman we make our military, the more unsafe Americans will feel and become.

## Offensive Realism

## The Role of Civil Society and Protest in American Security

## The Law of Unintended Consequences

## Everlasting War

## Chickens Coming Home to Roost
